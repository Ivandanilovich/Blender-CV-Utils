{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import os\n",
    "import torch\n",
    "from skimage.measure import find_contours\n",
    "from visualization_utils.visualization import draw_on_image\n",
    "\n",
    "from blender_cv_utils.projection_camera import apply_object_matrix_world, project_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_visibility_to_skeleton(skeleton, mask):\n",
    "    visibility = []\n",
    "    for i in skeleton.round().astype(np.int32):\n",
    "        for x, y, z in i:\n",
    "            if x < 0 or y < 0 or x >= mask.shape[0] or y >= mask.shape[1]:\n",
    "                visibility.append(-1)\n",
    "            else:\n",
    "                visibility.append(mask[x, y])\n",
    "    visibility_array = np.array(visibility)\n",
    "    visibility_reshaped = visibility_array.reshape(-1, 2)[..., None]\n",
    "    skeleton_with_visibility = np.concatenate((skeleton, visibility_reshaped), axis=-1)\n",
    "    return skeleton_with_visibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_name = 'Camera.001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dcfd1e6c62847718851a60db9dab854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1008 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = 'C:/Users/ivand/Desktop/output_temp/default_sc1/'\n",
    "\n",
    "global_params = json.load(open(os.path.join(path, 'global_params.json'), 'r'))\n",
    "\n",
    "all_data = []\n",
    "for annot_path in tqdm(sorted(Path(path).rglob('annots_frame*.json'))):\n",
    "     n = int(annot_path.name.replace('annots_frame', '').replace('.json', ''))\n",
    "     im = cv2.imread(os.path.join(path, f'{camera_name}_{n:04}.png'))\n",
    "     data = json.load(\n",
    "         open(os.path.join(path, f'annots_frame{n:04}.json'), 'r'))\n",
    "     data[camera_name].update(global_params)\n",
    "\n",
    "     objects_data = {}\n",
    "     for index, i in enumerate(['Armature', 'Armature.001', 'Armature.002', 'Armature.003', 'Armature.004', ]):\n",
    "            skeleton = []\n",
    "            for name, bone in data[i]['pose'].items():\n",
    "                if name in ['Bone.012.R.001', 'Bone.012.L.001', 'Bone.008.R.001', 'Bone.008.L.001', 'Bone.020']:  # IK bones\n",
    "                    continue\n",
    "                points = np.stack([np.array(bone['head']), np.array(bone['tail'])])\n",
    "                points = apply_object_matrix_world(points, data[i]['matrix_world'])\n",
    "                points = project_points(points, **data[camera_name]).numpy()\n",
    "                dh = torch.dist(torch.tensor(np.array(data[camera_name]['matrix_world'])[:-1,3]), torch.tensor(bone['head']), p=2).item()\n",
    "                dt = torch.dist(torch.tensor(np.array(data[camera_name]['matrix_world'])[:-1,3]), torch.tensor(bone['tail']), p=2).item()\n",
    "                points = np.concatenate((points, np.array([dh,dt])[...,None]), axis=1)\n",
    "                skeleton.append(points)\n",
    "            skeleton = np.stack(skeleton)\n",
    "            \n",
    "            mesh = data[data[i]['childrens'][0]]\n",
    "            mask = plt.imread(os.path.join(path, mesh[\"name\"], f'{camera_name}_{n:04}.png'))\n",
    "            mask = (mask[:,:,0] > 0.01).astype(np.uint8)\n",
    "\n",
    "            skeleton = add_visibility_to_skeleton(skeleton, mask)\n",
    "\n",
    "        #     xraymask = plt.imread(os.path.join(path, mesh[\"name\"], f'xray_{camera_name}_{n:04}.png'))[:, :, 3]\n",
    "  \n",
    "            im = draw_on_image(im, mask)\n",
    "         \n",
    "            contours = find_contours(mask.T, 0.5)\n",
    "            contours = [np.array(i).round().astype(np.int32) for i in contours]\n",
    "            contours = np.concatenate(contours)\n",
    "            xmin, xmax = np.min(contours[:, 0]), np.max(contours[:, 0])\n",
    "            ymin, ymax = np.min(contours[:, 1]), np.max(contours[:, 1])\n",
    "            objects_data[i] = {\n",
    "                'box':(xmin, ymin, xmax, ymax),\n",
    "                'mask':mask[ymin:ymax, xmin:xmax],\n",
    "                'sk': skeleton,  \n",
    "                'impath':os.path.join(path, f'{camera_name}_{n:04}.png'),\n",
    "            }\n",
    "\n",
    "     all_data.append(objects_data)\n",
    "    #  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(all_data, open(f'{path}/tempdata.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blender-cv-utils-rZc3flFA-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
