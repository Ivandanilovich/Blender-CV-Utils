{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import os\n",
    "import torch\n",
    "from skimage.measure import find_contours\n",
    "from visualization_utils.visualization import draw_on_image\n",
    "\n",
    "from blender_cv_utils.projection_camera import apply_object_matrix_world, project_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_visibility_to_skeleton(skeleton, mask):\n",
    "    visibility = []\n",
    "    for i in skeleton.round().astype(np.int32):\n",
    "        for x, y, z in i:\n",
    "            if x < 0 or y < 0 or x >= mask.shape[1] or y >= mask.shape[0]:\n",
    "                visibility.append(-1)\n",
    "            else:\n",
    "                visibility.append(mask[y, x])\n",
    "    visibility_array = np.array(visibility)\n",
    "    visibility_reshaped = visibility_array.reshape(-1, 2)[..., None]\n",
    "    skeleton_with_visibility = np.concatenate((skeleton, visibility_reshaped), axis=-1)\n",
    "    return skeleton_with_visibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_name = 'Camera.001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/ivand/Desktop/output_temp/default_sc1/'\n",
    "\n",
    "global_params = json.load(open(os.path.join(path, 'global_params.json'), 'r'))\n",
    "\n",
    "all_data = []\n",
    "for annot_path in tqdm(sorted(Path(path).rglob('annots_frame*.json'))):\n",
    "     n = int(annot_path.name.replace('annots_frame', '').replace('.json', ''))\n",
    "     im = cv2.imread(os.path.join(path, f'{camera_name}_{n:04}.png'))\n",
    "     data = json.load(\n",
    "         open(os.path.join(path, f'annots_frame{n:04}.json'), 'r'))\n",
    "     data[camera_name].update(global_params)\n",
    "\n",
    "     objects_data = {}\n",
    "     for index, i in enumerate(['Armature', 'Armature.001', 'Armature.002', 'Armature.003', 'Armature.004', ]):\n",
    "            skeleton = []\n",
    "            for name, bone in data[i]['pose'].items():\n",
    "                if name in ['Bone.012.R.001', 'Bone.012.L.001', 'Bone.008.R.001', 'Bone.008.L.001', 'Bone.020']:  # IK bones\n",
    "                    continue\n",
    "                points = np.stack([np.array(bone['head']), np.array(bone['tail'])])\n",
    "                points_transformed = apply_object_matrix_world(points, data[i]['matrix_world'])\n",
    "                points = project_points(points_transformed, **data[camera_name]).numpy()\n",
    "                dh = torch.dist(torch.tensor(np.array(data[camera_name]['matrix_world'])[:-1,3]), torch.tensor(points_transformed[0]), p=2).item()\n",
    "                dt = torch.dist(torch.tensor(np.array(data[camera_name]['matrix_world'])[:-1,3]), torch.tensor(points_transformed[1]), p=2).item()\n",
    "                points = np.concatenate((points, np.array([dh,dt])[...,None]), axis=1)\n",
    "                skeleton.append(points)\n",
    "            skeleton = np.stack(skeleton)\n",
    "            \n",
    "            mesh = data[data[i]['childrens'][0]]\n",
    "            mask = plt.imread(os.path.join(path, mesh[\"name\"], f'{camera_name}_{n:04}.png'))\n",
    "            mask = (mask[:,:,0] > 0.01).astype(np.uint8)\n",
    "\n",
    "            skeleton = add_visibility_to_skeleton(skeleton, mask)\n",
    "\n",
    "        #     xraymask = plt.imread(os.path.join(path, mesh[\"name\"], f'xray_{camera_name}_{n:04}.png'))[:, :, 3]\n",
    "  \n",
    "            im = draw_on_image(im, mask)\n",
    "         \n",
    "            contours = find_contours(mask.T, 0.5)\n",
    "            contours = [np.array(i).round().astype(np.int32) for i in contours]\n",
    "            contours = np.concatenate(contours)\n",
    "            xmin, xmax = np.min(contours[:, 0]), np.max(contours[:, 0])\n",
    "            ymin, ymax = np.min(contours[:, 1]), np.max(contours[:, 1])\n",
    "            objects_data[i] = {\n",
    "                'box':(xmin, ymin, xmax, ymax),\n",
    "                'mask':mask[ymin:ymax, xmin:xmax],\n",
    "                'sk': skeleton,  \n",
    "                'impath':os.path.join(path, f'{camera_name}_{n:04}.png'),\n",
    "            }\n",
    "\n",
    "     all_data.append(objects_data)\n",
    "    #  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(all_data, open(f'{path}/tempdata.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from visualization_utils.visualization import draw_on_image, skeleton_map_to_edges\n",
    "edges = skeleton_map_to_edges(json.load(open('C:/Users/ivand/Desktop/output_temp/default_sc1/skeletons.json'))['Armature'],\n",
    "                              excluded_bones=['Bone.012.R.001', 'Bone.012.L.001', 'Bone.008.R.001', 'Bone.008.L.001', 'Bone.020'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for N, sample in enumerate(all_data):\n",
    "\n",
    "    objects_names = list(sample.keys())\n",
    "    impath = sample[objects_names[0]]['impath']\n",
    "    image = cv2.cvtColor(cv2.imread(impath), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    h,w,_ = image.shape\n",
    "\n",
    "    bboxes = []\n",
    "    landmarks = []\n",
    "    instances_number = len(sample)\n",
    "    placeholder = np.zeros((instances_number,h,w), dtype=np.int32)\n",
    "\n",
    "    for n, i in enumerate(sample.values()):\n",
    "        xmin,ymin,xmax,ymax = i['box']\n",
    "        bboxes.append((xmin,ymin,xmax,ymax, n)) # n is id of instance\n",
    "        placeholder[n, ymin:ymax,xmin:xmax] = i['mask']\n",
    "        landmarks.append(i['sk'])\n",
    "\n",
    "    landmarks = np.concatenate(landmarks)\n",
    "    landmarks = landmarks[:,0,:] # select only heads\n",
    "\n",
    "    if np.any(landmarks[:,-1]==-1):\n",
    "        landmarks[landmarks[:,-1]==-1, 0:2] = 0\n",
    "\n",
    "    sample = {\n",
    "        'image': image.astype(np.float32), \n",
    "        'keypoints': landmarks, \n",
    "        'masks': placeholder, \n",
    "        'bboxes': np.array(bboxes)}\n",
    "    \n",
    "    im = draw_on_image(image, skeletons=sample['keypoints'].reshape(-1, 34, 4), edges=edges)\n",
    "    plt.imshow(im); plt.show()\n",
    "    if N>10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blender-cv-utils-rZc3flFA-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
